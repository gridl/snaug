{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, we have GPU!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_check = tf.test.gpu_device_name()\n",
    "#print(tf.test.gpu_device_name(),'\\n')\n",
    "if 'GPU' in gpu_check:\n",
    "    print(\"Yes, we have GPU!\")\n",
    "else:\n",
    "    print(\"No GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "ok64ThP9su5E",
    "outputId": "0646a5c0-c27e-4453-a655-b0809b97dc5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e79nIvIEsxUV",
    "outputId": "96b73a72-bb43-465f-9451-5c3d64411696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gdrive'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WbFDVVMFsxW5",
    "outputId": "1f66e770-c540-4936-eb4d-83beb13fbc4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gdrive/My Drive/data\n"
     ]
    }
   ],
   "source": [
    "cd 'My Drive/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "a04PCiBVsxYM",
    "outputId": "a9c85d46-724c-4ecb-81ad-07af8d739fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathfinder_deadly_mine.txt\tshakespeare_final.txt\n",
      "pathfinder_token_sequences.txt\ttextgen_pathfinder.txt\n"
     ]
    }
   ],
   "source": [
    "!ls *txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UjS6zQGVsH3M",
    "outputId": "00991023-7ba1-44b8-cf91-40d85d63744b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import string\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from keras.layers import LSTM, CuDNNLSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edkbJ_lp4M1Z"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9cnG8yMDzuK"
   },
   "outputs": [],
   "source": [
    "# load\n",
    "in_filename = 'data/pathfinder_token_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkQ6opdyqyRK"
   },
   "outputs": [],
   "source": [
    "sentences = [line.split() for line in lines]\n",
    "#sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = pickle.load(open('model/pathfinder_token_w2v300_word_model.pkl', 'rb'))\n",
    "pretrained_weights = pickle.load(open('model/pathfinder_token_w2v300_weights.pkl', 'rb'))\n",
    "\n",
    "tokenizer = pickle.load(open('model/pathfinder_token_tokenizer.pkl', 'rb'))\n",
    "\n",
    "#model = load_model('model/pathfinder_token_w2v_model_100_epoch.h5')\n",
    "#model = pickle.load(open('pathfinder_token_w2v_model_100_epoch.pkl', 'rb'))\n",
    "\n",
    "#history = pickle.load(open('model/pathfinder_token_w2v_model_100_epoch_history.pkl', 'rb'))\n",
    "\n",
    "#model.load_weights(\"model/pathfinder_token_w2v_model_100_epoch_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result embedding shape: (2925, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = word_model.wv.syn0\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         877500    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 300)         721200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2926)              880726    \n",
      "=================================================================\n",
      "Total params: 3,290,926\n",
      "Trainable params: 3,290,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "#model.add(Embedding(vocab_size, 100, input_length=seq_length))\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights]))\n",
    "\n",
    "model.add(LSTM(emdedding_size, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(emdedding_size))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(emdedding_size, activation='relu'))\n",
    "\n",
    "model.add(Dense((vocab_size+1), activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model/pathfinder_token_w2v_model_100_epoch_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "uOVg0YcqqWdx",
    "outputId": "d5e55fd6-d176-48e9-f072-24a873a8dd07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training word2vec...\n",
      "Result embedding shape: (2925, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining word2vec...')\n",
    "# workers=1 will ensure a fully deterministrically-reproducible run, per Gensim docs\n",
    "word_model = gensim.models.Word2Vec(sentences, size=300, min_count=1, window=5, iter=100, workers=1)\n",
    "pretrained_weights = word_model.wv.syn0\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "6Et-o05WqvlS",
    "outputId": "63c55bf4-5177-4a08-9131-8a60371f66b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking similar words:\n",
      "  gold -> studded (0.31), empathize (0.26), not (0.25), communicate (0.25), here (0.24), investigating (0.23), provide (0.23), engraved (0.23)\n",
      "  goblin -> warriors (0.54), reckless (0.47), tries (0.40), fights (0.36), pound (0.36), ac (0.36), acquired (0.34), accessible (0.33)\n",
      "  magic -> largest (0.37), korvosan (0.36), minor (0.36), acadamae (0.34), radiate (0.33), torches (0.30), initially (0.30), identifies (0.29)\n",
      "  priest -> sole (0.82), birm (0.80), curate (0.66), amelon (0.65), temple (0.54), desna (0.48), archways (0.45), sun (0.43)\n",
      "  mine -> hillside (0.30), energy (0.29), movement (0.26), lowdown (0.25), second (0.23), cracked (0.22), managed (0.22), arts (0.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print('Checking similar words:')\n",
    "for word in ['gold', 'goblin', 'magic', 'priest', 'mine']:\n",
    "    most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in word_model.most_similar(word)[:8])\n",
    "    print('  %s -> %s' % (word, most_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4xA4oqxqwue"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5douivHx14Yg"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pslBEhSYSyGH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2D1PMbKFqO8"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYwfxTM551Ct"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAOO8GR_hIN1"
   },
   "outputs": [],
   "source": [
    "def sample_word(preds, temperature=1.0):\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fy1WC2CAwcUJ"
   },
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words, temperature=0):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        #   [0] coz shape is (num_lines, num_tokens_per_line)\n",
    "        #   and there is only one line right now\n",
    "        #   also num_tokens is not a const, hence trunc will be required\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed lenght\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        #yhat = model.predict_classes(encoded, verbose=0)\n",
    "        yhat = sample_word(model.predict(encoded,verbose=0)[-1], temperature)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knvw5qPvUj48"
   },
   "outputs": [],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'data/pathfinder_token_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "id": "ANNaUjCh6mr7",
    "outputId": "9a0f6b3a-eef5-4bba-e1fb-56fdbbb32fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "#model = load_model('pathfinder_token_model_300_epoch.h5')\n",
    "#model = load_model('pathfinder_token_model_250_epoch.h5')\n",
    "#model = load_model('pathfinder_token_model_150_epoch.h5')\n",
    "#model = load_model('pathfinder_token_model_200_epoch.h5')\n",
    "model = load_model('pathfinder_token_w2v_model_100_epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9un1hyW6mvx"
   },
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = pickle.load(open('model/pathfinder_token_tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "NtwyuGmxhJyq",
    "outputId": "42ff0a95-cab2-4188-ae3c-e7c9e70f7b11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the giant black widow spider is a tough cr poisonous spider the marsh dwelling lizardfolk can be dangerous enemies or cautiously the flesh eating minotaur is a tough solo opponent for higher level characters or the deadly boss of a tribe of orcs or goblins the wererat is a sneaky shapeshifter',\n",
       " 'giant black widow spider is a tough cr poisonous spider the marsh dwelling lizardfolk can be dangerous enemies or cautiously the flesh eating minotaur is a tough solo opponent for higher level characters or the deadly boss of a tribe of orcs or goblins the wererat is a sneaky shapeshifter relying',\n",
       " 'black widow spider is a tough cr poisonous spider the marsh dwelling lizardfolk can be dangerous enemies or cautiously the flesh eating minotaur is a tough solo opponent for higher level characters or the deadly boss of a tribe of orcs or goblins the wererat is a sneaky shapeshifter relying on',\n",
       " 'widow spider is a tough cr poisonous spider the marsh dwelling lizardfolk can be dangerous enemies or cautiously the flesh eating minotaur is a tough solo opponent for higher level characters or the deadly boss of a tribe of orcs or goblins the wererat is a sneaky shapeshifter relying on stealth',\n",
       " 'spider is a tough cr poisonous spider the marsh dwelling lizardfolk can be dangerous enemies or cautiously the flesh eating minotaur is a tough solo opponent for higher level characters or the deadly boss of a tribe of orcs or goblins the wererat is a sneaky shapeshifter relying on stealth and']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)\n",
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "YVfp-3Ff6muC",
    "outputId": "76a8aa25-9ee8-4c24-f314-0748e8861d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "night air emanating from the graveyard west of town and because of their\n",
      "superstition refuse to go out at night rumors suggest that another of the\n",
      "twilight fell rituals must have gone awry stoic and resigned the peasants seem\n",
      "to accept their self imposed curfew as their lot in life and\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(textwrap.fill('%s' % (seed_text), 80) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9HbTEMwXB3r"
   },
   "outputs": [],
   "source": [
    "#seed_text='lycanthropes living in the area albeit fearfully and in hiding run a farmer off his or her land so they could move in So farthough a few savagely mauled farm animals have not been sufficient motivation to scare off any of the farmers and Shala has decided it time to try a more'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5ee20eiJlcn"
   },
   "outputs": [],
   "source": [
    "#seed_text='fearfully and in hiding run a farmer off his or her land so they could move in so farthough'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "FYIfsm0BVMON",
    "outputId": "5f49d5c0-314d-4b53-fb6c-ccb5116a4d56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ringoshin/.Envs/pfbot/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give any signs that they feel anything needs to change if captain silva any pc\n",
      "who elaborates on the battle if he full behind them the candle of night for the\n",
      "relics and making an levitate voice gp to gold elements in the watch the envoy\n",
      "at a cleric of potions from her desk the bottle contains a strong throat and a\n",
      "document alcohol that on the false scepter upon a bottle labeled discovering\n",
      "that\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 75, 1.5)\n",
    "print(textwrap.fill('%s' % (generated), 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuhSv6uoDEy8"
   },
   "outputs": [],
   "source": [
    "special_gen=\"\"\"few weeks ago and have not yet returned the three missing monks are piotr oja\n",
    "ollie lenstraand tibaldo russo brother joachim informs the pcs there is a cave\n",
    "that has been used for shelter in the mountains along the route to galduria and\n",
    "describes how the pcs can locate it as the pcs travel further north they can see\n",
    "and feel approach small patches of snow linger in shaded areas the grasses are a\n",
    "dull\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "7CXG9UoFCZlj",
    "outputId": "8718bf29-3c24-4e02-c038-b3909ada997e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few weeks ago and have not yet returned the three missing monks are piotr oja\n",
      "ollie lenstraand tibaldo russo brother joachim informs the pcs there is a cave\n",
      "that has been used for shelter in the mountains along the route to galduria and\n",
      "describes how the pcs can locate it as the pcs travel further north they can see\n",
      "and feel approach small patches of snow linger in shaded areas the grasses are a\n",
      "dull\n"
     ]
    }
   ],
   "source": [
    "generated = special_gen\n",
    "print(textwrap.fill('%s' % (generated), 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJxONZMPzoQt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "Smj_dEKbrfLH",
    "outputId": "b8213382-7fe2-498c-8a63-d8718c8b3919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
      "\u001b[K     |████████████████████████████████| 826.9MB 50.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=4a5fa3714e13de0fd9a3bc1bc9c2007859cb752ec07b8662f352dec45e0bb59f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1mz0tldt/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbzO2lDfn_1B"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "#import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "s9RQr5Nzn_23",
    "outputId": "1c7cdda4-e0f6-49a0-aec0-c5a9c6bad864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(few, 'DATE'), (weeks, 'DATE'), (ago, 'DATE'), (three, 'CARDINAL'), (piotr, 'PERSON'), (oja, 'PERSON'), (\n",
      ", 'PERSON'), (ollie, 'PERSON'), (tibaldo, 'PERSON'), (russo, 'PERSON'), (joachim, 'PERSON'), (galduria, 'GPE')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    few weeks ago\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and have not yet returned the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " missing monks are \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    piotr oja\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    ollie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " lenstraand \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    tibaldo russo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " brother \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    joachim\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " informs the pcs there is a cave</br>that has been used for shelter in the mountains along the route to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    galduria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and\n",
       "describes how the pcs can locate it as the pcs travel further north they can see\n",
       "and feel approach small patches of snow linger in shaded areas the grasses are a\n",
       "dull</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_nlp = nlp(generated)\n",
    "\n",
    "# print named entities in article\n",
    "print([(word, word.ent_type_) for word in sentence_nlp if word.ent_type_])\n",
    "\n",
    "# visualize named entities\n",
    "displacy.render(sentence_nlp, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sniDYrM4iPw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weeks', 'NOUN', 'week')\n",
      "('monks', 'NOUN', 'monk')\n",
      "('brother', 'NOUN', 'brother')\n",
      "('pcs', 'NOUN', 'pc')\n",
      "('cave', 'NOUN', 'cave')\n",
      "('shelter', 'NOUN', 'shelter')\n",
      "('mountains', 'NOUN', 'mountain')\n",
      "('route', 'NOUN', 'route')\n",
      "('pcs', 'NOUN', 'pc')\n",
      "('pcs', 'NOUN', 'pc')\n",
      "('approach', 'NOUN', 'approach')\n",
      "('patches', 'NOUN', 'patch')\n",
      "('snow', 'NOUN', 'snow')\n",
      "('areas', 'NOUN', 'area')\n",
      "('grasses', 'NOUN', 'grass')\n"
     ]
    }
   ],
   "source": [
    "#[(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "#                                      for y\n",
    "#                                      in nlp(generated)\n",
    "#                                      if (not y.is_stop and y.pos_ != 'PUNCT') or y.pos_ == 'NUM']]\n",
    "noun_list = []\n",
    "for token in nlp(generated):\n",
    "#    if (not token.is_stop and token.pos_ != 'PUNCT') or token.pos_ == 'NUM':\n",
    "    if (token.pos_ == 'NOUN'):\n",
    "        noun_list.append(token)\n",
    "        print((token.orth_,token.pos_, token.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "BIicC96BOfYf",
    "outputId": "3bf5a960-0c3e-4134-f07b-dd42fc972dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cave shelter 0.3689129\n",
      "cave mountains 0.5231152\n",
      "shelter mountains 0.3393006\n",
      "mountains snow 0.5963584\n",
      "cave brother 0.22205521\n"
     ]
    }
   ],
   "source": [
    "#print([(i, noun) for i, noun in enumerate(noun_list)])\n",
    "#print(doc[7], doc[8], doc[7].similarity(doc[8]))\n",
    "test_doc = nlp('cave shelter mountains snow brother')\n",
    "print(test_doc[0], test_doc[1], test_doc[0].similarity(test_doc[1]))\n",
    "print(test_doc[0], test_doc[2], test_doc[0].similarity(test_doc[2]))\n",
    "print(test_doc[1], test_doc[2], test_doc[1].similarity(test_doc[2]))\n",
    "print(test_doc[2], test_doc[3], test_doc[2].similarity(test_doc[3]))\n",
    "print(test_doc[0], test_doc[4], test_doc[0].similarity(test_doc[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxeUIHYmO_bA"
   },
   "outputs": [],
   "source": [
    "vocab_dict = word_model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GogUvMQ8zwR8"
   },
   "outputs": [],
   "source": [
    "vocab = [k for k in vocab_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8TWGOGZ2zwQT",
    "outputId": "6982db4a-684c-4d6c-d519-3646b4e90469"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2925"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "QkGLfyiP0_5M",
    "outputId": "9803fa53-c296-4df3-88f8-a9115e5fdfd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv_glove = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2wzh-tU0_8W"
   },
   "outputs": [],
   "source": [
    "for word in ['gold', 'goblin', 'magic', 'priest', 'mine']:\n",
    "    most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in wv_glove.most_similar(word)[:8])\n",
    "    print('  %s -> %s' % (word, most_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eo5qskU61AA0"
   },
   "outputs": [],
   "source": [
    "for word in ['zimandi', 'goblin', 'magic', 'priest', 'mine']:\n",
    "    most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in word_model.most_similar(word)[:8])\n",
    "    print('  %s -> %s' % (word, most_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "NCjdjcZa4syp",
    "outputId": "177cad3e-a206-4ca5-da1c-3a3e976e688e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "not_found_list, name_list, oov_list = [], [], []\n",
    "skip_words = ['darkvision', 'bracers', 'dungeoneering', 'ungracefully', 'lycanthropic', 'starknife' ]\n",
    "for word,i in word_model.wv.vocab.items():\n",
    "    try:\n",
    "        embedding_vector = wv_glove.wv[word] \n",
    "    except:\n",
    "        not_found_list.append(word)\n",
    "        if word not in skip_words:\n",
    "            name_list.append(word)\n",
    "        else:\n",
    "            oov_list.append(word)\n",
    "        #print(word, 'not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jvnq11in0r7j"
   },
   "outputs": [],
   "source": [
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_WJbZRlTPiX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "eWsMWgJ4Abh2",
    "outputId": "5617ac44-a133-4173-b981-0edea6f291fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the three missing monks | monks | nsubj | are\n",
      "piotr oja | oja | attr | are\n",
      "ollie lenstraand tibaldo russo brother | brother | nsubj | informs\n",
      "joachim | joachim | appos | brother\n",
      "the pcs | pcs | dobj | informs\n",
      "a cave | cave | attr | is\n",
      "that | that | nsubjpass | used\n",
      "shelter | shelter | pobj | for\n",
      "the mountains | mountains | pobj | in\n",
      "the route | route | pobj | along\n",
      "galduria | galduria | pobj | to\n",
      "the pcs | pcs | nsubj | locate\n",
      "it | it | dobj | locate\n",
      "the pcs | pcs | nsubj | travel\n",
      "they | they | nsubj | see\n",
      "small patches | patches | nsubj | linger\n",
      "snow | snow | pobj | of\n",
      "shaded areas | areas | pobj | in\n",
      "the grasses | grasses | nsubj | are\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(generated)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(\"{} | {} | {} | {}\".format(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "aax02VAYAc4V",
    "outputId": "8f2100e4-452f-4eb8-91b3-8e8e4b26a726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before [('FB', 0, 2, 'ORG')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E103] Trying to set conflicting doc.ents: '(0, 1, 'ORG')' and '(0, 1, 'GOD')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4cf392f9c0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mORG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mu\"ORG\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# get hash value of entity label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfb_ent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GOD'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create a Span for the new entity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfb_ent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0ments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E103] Trying to set conflicting doc.ents: '(0, 1, 'ORG')' and '(0, 1, 'GOD')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(u\"FB is hiring a new Vice President of global policy\")\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('Before', ents)\n",
    "# the model didn't recognise \"FB\" as an entity :(\n",
    "\n",
    "DATE = doc.vocab.strings[u\"DATE\"]  # get hash value of entity label\n",
    "ORG = doc.vocab.strings[u\"ORG\"]  # get hash value of entity label\n",
    "fb_ent = Span(doc, 0, 1, label='GOD') # create a Span for the new entity\n",
    "doc.ents = list(doc.ents) + [fb_ent]\n",
    "\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('After', ents)\n",
    "# [(u'FB', 0, 2, 'MOG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kHDI_Ky7Ac86",
    "outputId": "c25e68a1-d089-46ac-9bf9-c8a0e928a871"
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ww91O-Yab3GH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CEHSgIVh-0B"
   },
   "outputs": [],
   "source": [
    "god_list = ['Erastil', 'Aroden', 'Desna', 'Sarenrae']\n",
    "race_list = ['Azlanti', 'Varisian', 'Thassilonian', 'Korvosan', 'Magnimarian']\n",
    "org_list = ['Runelord', 'Runelords', 'Rockwhelp', 'Academae', 'Versade', \n",
    "            'Pathfinder', 'Society']\n",
    "monster_list = ['wererat', 'wererats', 'werewolf', 'Yarg', 'goblin', 'goblins', \n",
    "                'orc', 'orcs', 'spider', 'spiders', 'minotaur', 'elemental', \n",
    "                'wolf', 'lycanthropes', 'lycanthrope', 'Cheh', 'Kavoos', 'Shala',\n",
    "                'undead', 'ghouls']\n",
    "person_list = ['Eberius', 'Tauranor', 'Xanderghul', 'Sheila', 'Heidmarch',\n",
    "               'Hork', 'Shalesmash', 'Amelon', 'Birm', 'Grald', 'Hazelindra', \n",
    "               'Linna', 'Montrovale', 'Gorbic', 'Salmore', 'Mena', 'Zamola', 'Duso', 'Galino',\n",
    "               'Piotr', 'Oja', 'Ollie', 'Lenstraand', 'Tibaldo', 'Russo', 'Joachim',\n",
    "               'Aldemar', 'Lenstra', 'Jargie', 'Krzysztof', 'Szabo', 'Shabana', 'Neergah', \n",
    "               'Elliana', 'Silva', 'Savasha', 'Versade', 'Nindrik', 'Versade', 'Hobart', 'Deverin',\n",
    "               'Kendra', 'Deverin', 'Gradon', 'Scarnetti', 'Zimandi', 'Kaddren', 'Cheiskaia', 'Nirodin',\n",
    "               'Gradon', 'Scarnetti', 'Tauk', 'Yordan', 'Zorakov', 'Lucas', 'Gustavo', 'Kantaro',\n",
    "               'Das', 'Korvut', 'Zanthus', 'Belor', 'Durn', 'Belor', 'Hemlock', 'Pavlina']\n",
    "location_list = ['Golarion', 'Varisia', 'Lurkwood', 'Riddleport', 'Galduria', \n",
    "                 'Acadamae', 'Korvosa', 'Thassilon',  'Magnimar', 'Irespan', \n",
    "                 'Dockway', 'Sandpoint', 'Brinestump', 'Marsh', 'Soggy', 'River', \n",
    "                 'Windsong', 'Abbey', 'Rusty', 'Dragon', 'Necropolis']\n",
    "spell_list = ['Burning', 'Hands']\n",
    "long_name_list = god_list + race_list + org_list + monster_list + person_list + location_list + spell_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLXzQud6sdBO"
   },
   "outputs": [],
   "source": [
    "god_labels = ['Erastil', 'Aroden', 'Desna', 'Sarenrae']\n",
    "race_labels = ['Azlanti', 'Varisian', 'Thassilonian', 'Korvosan', 'Magnimarian']\n",
    "org_labels = ['Runelord', 'Runelords', 'Aockwhelp', 'Academae', 'Versade',\n",
    "             'Pathfinder Society']\n",
    "monster_labels = ['wererat', 'wererats', 'werewolf', 'Yarg', 'goblin', 'goblins', \n",
    "                'orc', 'orcs', 'spider', 'spiders', 'minotaur', 'elemental', \n",
    "                'wolf', 'lycanthropes', 'lycanthrope', 'Cheh', 'Kavoos', 'Shala',\n",
    "                'undead', 'ghouls']\n",
    "person_labels = ['Eberius Tauranor', 'Xanderghul', 'Sheila Heidmarch',\n",
    "#               'Hork Shalesmash', 'Amelon Birm', 'Grald', 'Hazelindra', \n",
    "               'Hork', 'Amelon Birm', 'Grald', 'Hazelindra', \n",
    "               'Linna Montrovale', 'Gorbic Salmore', 'Mena Zamola', 'Duso Galino',\n",
    "               'Piotr Oja', 'Ollie Lenstraand', 'Tibaldo Russo', 'Joachim',\n",
    "               'Aldemar Lenstra', 'Jargie', 'Krzysztof Szabo', 'Shabana Neergah', \n",
    "               'Elliana Silva', 'Savasha Versade', 'Nindrik Versade', 'Hobart Deverin',\n",
    "               'Kendra Deverin', 'Gradon Scarnetti', 'Zimandi Kaddren', 'Cheiskaia Nirodin',\n",
    "               'Gradon Scarnetti', 'Tauk', 'Yordan Zorakov', 'Lucas', 'Gustavo', 'Kantaro',\n",
    "               'Das Korvut', 'Zanthus', 'Belor', 'Durn', 'Belor Hemlock', 'Pavlina']\n",
    "location_labels = ['Golarion', 'Varisia', 'Lurkwood', 'Riddleport', 'Galduria', \n",
    "                 'Acadamae', 'Korvosa', 'Thassilon',  'Magnimar', 'Irespan', \n",
    "                 'Dockway', 'Sandpoint', 'Brinestump Marsh', 'Soggy River', 'Windsong Abbey', \n",
    "                  'Rusty Dragon', 'Necropolis']\n",
    "spell_labels = ['Burning Hands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMrB5HiyqEHJ"
   },
   "outputs": [],
   "source": [
    "def Entity_Type(word):\n",
    "    word_lower = word\n",
    "    word = word[0].upper() + word[1:]\n",
    "    if word in god_list:\n",
    "        return 'GOD', word\n",
    "    elif word in race_list:\n",
    "        return 'RACE', word\n",
    "    elif word in org_list:\n",
    "        return 'ORG', word\n",
    "    elif word in monster_list:\n",
    "        return 'MOB', word\n",
    "    elif word_lower in monster_list:\n",
    "        return 'MOB', word_lower \n",
    "    elif word in person_list:\n",
    "        return 'PER', word\n",
    "    elif word in location_list:\n",
    "        return 'LOC', word\n",
    "    elif word in spell_list:\n",
    "        return 'SP', word\n",
    "    else:\n",
    "        return 'UNK', word_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "95OI68mXMtPV",
    "outputId": "e7e96bc6-fe88-4288-ff9b-3a455ec26a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sarenrae: ('GOD', 'Sarenrae')\n",
      "was: ('UNK', 'was')\n",
      "mentioned: ('UNK', 'mentioned')\n",
      "but: ('UNK', 'but')\n",
      "tauranor: ('PER', 'Tauranor')\n",
      "did: ('UNK', 'did')\n",
      "not: ('UNK', 'not')\n",
      "think: ('UNK', 'think')\n",
      "goblins: ('MOB', 'goblins')\n",
      "are: ('UNK', 'are')\n",
      "in: ('UNK', 'in')\n",
      "korvosa: ('LOC', 'Korvosa')\n"
     ]
    }
   ],
   "source": [
    "test_words = ['sarenrae', 'was', 'mentioned', 'but', 'tauranor', 'did', 'not', 'think', 'goblins', 'are','in', 'korvosa']\n",
    "for word in test_words:\n",
    "    print(\"{}: {}\".format(word, Entity_Type(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nukiGzxlNRj3"
   },
   "outputs": [],
   "source": [
    "generated = 'so sarenrae is mentioned adn there are goblins too in Korvosa praying to runelords and varisian and kantaro ' + generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSDda-R4LQ0g"
   },
   "outputs": [],
   "source": [
    "generated='of aroden before he rose to godhood thousands of years ago while the veracity of the origin remains unconfirmed the arcane spells within are worth investigation by the pathfinder society and perhaps the diviners in the organization can determine the true nature to make good her escape she contacted venture'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7yX_sai4kGF"
   },
   "outputs": [],
   "source": [
    "g_new = ''\n",
    "g_god = []\n",
    "g_mob = []\n",
    "g_per = []\n",
    "g_loc = []\n",
    "g_race = []\n",
    "g_org = []\n",
    "g_sp = []\n",
    "for g_word in generated.split():\n",
    "    g_type, g_word = Entity_Type(g_word)\n",
    "    if g_type=='GOD':\n",
    "        g_god.append(g_word)\n",
    "    elif g_type=='MOB':\n",
    "        g_mob.append(g_word)\n",
    "    elif g_type=='PER':\n",
    "        g_per.append(g_word)\n",
    "    elif g_type=='LOC':\n",
    "        g_loc.append(g_word)\n",
    "    elif g_type=='RACE':\n",
    "        g_race.append(g_word)\n",
    "    elif g_type=='ORG':\n",
    "        g_org.append(g_word)\n",
    "    elif g_type=='SP':\n",
    "        g_sp.append(g_word)\n",
    "    g_new  = ' '.join([g_new, g_word]) \n",
    "g_new = g_new.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_1vam-1_GOy5",
    "outputId": "6e0e1b16-3454-4af0-b131-0c16460dc422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of Aroden before he rose to godhood thousands of years ago while the veracity of the origin remains unconfirmed the arcane spells within are worth investigation by the Pathfinder Society and perhaps the diviners in the organization can determine the true nature to make good her escape she contacted venture'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1c8vNWg59wRb"
   },
   "outputs": [],
   "source": [
    "new_g_per=[]\n",
    "if len(g_per)>1:\n",
    "    x = iter(g_per)\n",
    "    first_name = next(x)\n",
    "    prev_fullname = ''\n",
    "    for _ in range(len(g_per)-1):\n",
    "        second_name = next(x)\n",
    "        full_name = '{} {}'.format(first_name, second_name)\n",
    "        if full_name in person_labels:\n",
    "            new_g_per.append(full_name)\n",
    "            prev_fullname = full_name\n",
    "        else:\n",
    "            if first_name in prev_fullname:\n",
    "                prev_fullname = ''\n",
    "            else:\n",
    "                new_g_per.append(first_name)\n",
    "        first_name = second_name\n",
    "    g_per = new_g_per\n",
    "    if first_name not in prev_fullname:\n",
    "        g_per.append(first_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N7mfAjvG6VfL",
    "outputId": "053bddff-41f4-4f01-cb71-c61364d0ac47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuLyQvVG6Wf7"
   },
   "outputs": [],
   "source": [
    "new_g_loc=[]\n",
    "if len(g_loc)>1:\n",
    "    x = iter(g_loc)\n",
    "    first_name = next(x)\n",
    "    prev_fullname = ''\n",
    "    for _ in range(len(g_loc)-1):\n",
    "        second_name = next(x)\n",
    "        full_name = '{} {}'.format(first_name, second_name)\n",
    "        if full_name in location_labels:\n",
    "            new_g_loc.append(full_name)\n",
    "            prev_fullname = full_name\n",
    "        else:\n",
    "            if first_name in prev_fullname:\n",
    "                prev_fullname = ''\n",
    "            else:\n",
    "                new_g_loc.append(first_name)\n",
    "        first_name = second_name\n",
    "    g_loc = new_g_loc\n",
    "    if first_name not in prev_fullname:\n",
    "        g_loc.append(first_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zCOLpS4_BcXz",
    "outputId": "af2b6ccc-d393-43e5-df5e-f9b750f76511"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oi5kJuXOZizj"
   },
   "outputs": [],
   "source": [
    "new_g_sp=[]\n",
    "if len(g_sp)>1:\n",
    "    x = iter(g_sp)\n",
    "    first_name = next(x)\n",
    "    prev_fullname = ''\n",
    "    for _ in range(len(g_sp)-1):\n",
    "        second_name = next(x)\n",
    "        full_name = '{} {}'.format(first_name, second_name)\n",
    "        if full_name in spell_labels:\n",
    "            new_g_sp.append(full_name)\n",
    "            prev_fullname = full_name\n",
    "        else:\n",
    "            if first_name in prev_fullname:\n",
    "                prev_fullname = ''\n",
    "            else:\n",
    "                new_g_sp.append(first_name)\n",
    "        first_name = second_name\n",
    "    g_sp = new_g_sp\n",
    "    if first_name not in prev_fullname:\n",
    "        g_sp.append(first_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZgFG848DZ3J5",
    "outputId": "36e3fb2b-46d2-435e-8b32-5e4588e9f091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9w35ZO4rcjeh"
   },
   "outputs": [],
   "source": [
    "new_g_org=[]\n",
    "if len(g_org)>1:\n",
    "    x = iter(g_org)\n",
    "    first_name = next(x)\n",
    "    prev_fullname = ''\n",
    "    for _ in range(len(g_org)-1):\n",
    "        second_name = next(x)\n",
    "        full_name = '{} {}'.format(first_name, second_name)\n",
    "        if full_name in org_labels:\n",
    "            new_g_org.append(full_name)\n",
    "            prev_fullname = full_name\n",
    "        else:\n",
    "            if first_name in prev_fullname:\n",
    "                prev_fullname = ''\n",
    "            else:\n",
    "                new_g_org.append(first_name)\n",
    "        first_name = second_name\n",
    "    g_org = new_g_org\n",
    "    if first_name not in prev_fullname:\n",
    "        g_org.append(first_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DouqcTg0cjiD",
    "outputId": "f64f4899-0955-47bf-a60b-d4a756233403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pathfinder Society']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj-Xs95jBdBI"
   },
   "outputs": [],
   "source": [
    "def List_Notables():\n",
    "    g_all = g_god + g_mob + g_per + g_loc + g_race + g_org\n",
    "    if g_all:\n",
    "        print('Notable(s) found:')\n",
    "        if g_god:\n",
    "            print(\"   God(s)     : {}\".format(', '.join(g_god)))\n",
    "        if g_mob:\n",
    "            print(\"   Monster(s) : {}\".format(', '.join(g_mob)))\n",
    "        if g_per:\n",
    "            print(\"   Person(s)  : {}\".format(', '.join(g_per)))\n",
    "        if g_sp:\n",
    "            print(\"   Spell(s)   : {}\".format(', '.join(g_sp)))\n",
    "        if g_loc:\n",
    "            print(\"   Location(s): {}\".format(', '.join(g_loc)))\n",
    "        if g_race:\n",
    "            print(\"   Race(s)    : {}\".format(', '.join(g_race)))\n",
    "        if g_org:\n",
    "            print(\"   Organisation(s): {}\".format(', '.join(g_org)))\n",
    "    else:\n",
    "        print(\">>> No notables found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "KX2IX51GDR7q",
    "outputId": "a20af289-e53b-4ea3-940f-884fdeeafeb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notable(s) found:\n",
      "   God(s)     : Aroden\n",
      "   Organisation(s): Pathfinder Society\n"
     ]
    }
   ],
   "source": [
    "List_Notables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YMTi4guE6Xl"
   },
   "outputs": [],
   "source": [
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSyDKgTUMPPZ"
   },
   "outputs": [],
   "source": [
    "god_patterns = [nlp(text) for text in god_labels]\n",
    "mob_patterns = [nlp(text) for text in monster_labels]\n",
    "per_patterns = list(nlp.pipe(person_labels))\n",
    "loc_patterns = list(nlp.pipe(location_labels))\n",
    "race_patterns = [nlp(text) for text in race_labels]\n",
    "org_patterns = [nlp(text) for text in org_labels]\n",
    "sp_patterns = [nlp(text) for text in spell_labels]\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add('GOD', None, *god_patterns)\n",
    "matcher.add('MOB', None, *mob_patterns)\n",
    "matcher.add('PER', None, *per_patterns)\n",
    "matcher.add('LOC', None, *loc_patterns)\n",
    "matcher.add('RACE', None, *race_patterns)\n",
    "matcher.add('ORG', None, *org_patterns)\n",
    "matcher.add('SP', None, *sp_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ZwlGITgoOLCH",
    "outputId": "3c0ce646-672d-4799-a462-471b1b9f6de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOD Aroden\n",
      "ORG Pathfinder Society\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(g_new)\n",
    "matches = matcher(doc)\n",
    "spans = []\n",
    "for match_id, start, end in matches:\n",
    "    rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "    span = doc[start : end]  # get the matched slice of the doc\n",
    "    print(rule_id, span.text)\n",
    "    spans.append(Span(doc, start, end, label=rule_id))\n",
    "    doc.ents = spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "BMGb0gngGU_I",
    "outputId": "a669df1a-7d4e-4d61-fc43-33319df29b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "You: Tell me about a tome penned by an apprentice.\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Snaug_bot:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">of \n",
       "<mark class=\"entity\" style=\"background: #f2865e; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Aroden\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GOD</span>\n",
       "</mark>\n",
       " before he rose to godhood thousands of years ago while the veracity of the origin remains unconfirmed the arcane spells within are worth investigation by the \n",
       "<mark class=\"entity\" style=\"background: #d88fff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pathfinder Society\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and perhaps the diviners in the organization can determine the true nature to make good her escape she contacted venture</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Notable(s) found:\n",
      "   God(s)     : Aroden\n",
      "   Organisation(s): Pathfinder Society\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print()\n",
    "print('You: {}'.format('Tell me about a tome penned by an apprentice.'))\n",
    "print('-'*95)\n",
    "options = {\"ents\": ['GOD','MOB','PER','LOC','RACE','ORG','SP'],\n",
    "           \"colors\": {'GOD':'#f2865e','MOB':'#58f549','PER':'#aef5ef',\n",
    "                      'LOC':'pink','RACE':'#edcb45','ORG':'#d88fff', 'SP':'pink'}}\n",
    "print('Snaug_bot:') \n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)\n",
    "print()\n",
    "List_Notables()\n",
    "print('-'*95)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0uT6nFWHqu0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "snaug_output_engine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
